{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2XM7PmEHRx9"
   },
   "source": [
    "### 5.3 Programming Task: Digit recognition using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCZp0iyAHgVr",
    "outputId": "d465e2f0-1cf8-4ebc-f402-32ec0f248e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmRh05rsHRx_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQwp6i7VHRyB"
   },
   "source": [
    "i. Complete the code for the ConvNet class given below using the network description from supplement pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3-zQCCxHRyB"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 1 x 28 x 28 -> 20 x 28 x 28\n",
    "            nn.Conv2d(1, 20, 5, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            # 20 x 28 x 28 -> 20 x 14 x 14\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 20 x 14 x 14 -> 3920\n",
    "            nn.Flatten(),\n",
    "            # 3920 -> 100\n",
    "            nn.Linear(3920, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKSe9R-qHRyC"
   },
   "source": [
    "Show the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voUQHWE2HRyC",
    "outputId": "0bd5e9ab-3b91-4392-c0ff-8fbd2b2850ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=3920, out_features=100, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kep3KigMHRyC"
   },
   "source": [
    "ii. Train the CNN and observe the difference in performance in comparison to the feed-forward\n",
    "network from the task 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFjbZQL6HRyD"
   },
   "outputs": [],
   "source": [
    "# Set hyper parameters.\n",
    "batch_size = 200\n",
    "lr = 1e-3\n",
    "n_epochs = 10\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YTcuSyqHRyD"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST data set.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lkYRCASHRyD"
   },
   "outputs": [],
   "source": [
    "# Set the loss function and the optimization criteria\n",
    "criterion = F.cross_entropy\n",
    "model = ConvNet().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xa5fIzPZHRyE",
    "outputId": "f975f9fd-4314-4fa6-e197-babfd1bd10b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 of 10, loss: 0.222977\n",
      "Train Epoch: 2 of 10, loss: 0.066667\n",
      "Train Epoch: 3 of 10, loss: 0.048316\n",
      "Train Epoch: 4 of 10, loss: 0.037190\n",
      "Train Epoch: 5 of 10, loss: 0.028477\n",
      "Train Epoch: 6 of 10, loss: 0.022841\n",
      "Train Epoch: 7 of 10, loss: 0.019759\n",
      "Train Epoch: 8 of 10, loss: 0.014732\n",
      "Train Epoch: 9 of 10, loss: 0.011986\n",
      "Train Epoch: 10 of 10, loss: 0.011634\n"
     ]
    }
   ],
   "source": [
    "# Run the main training loop\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    ep_train_loss = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        logits = model.forward(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        ep_train_loss.append(loss.item())\n",
    "    mean_ep_train_loss = sum(ep_train_loss) / len(ep_train_loss)\n",
    "    print(f'Train Epoch: {epoch + 1} of {n_epochs}, loss: {mean_ep_train_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORkLh5K1HRyE",
    "outputId": "f658312c-295e-4f3b-aa24-9b4e7c87fa0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0433, Accuracy: 9869/10000 (98.69%)\n"
     ]
    }
   ],
   "source": [
    "# Run the testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "test_loss = []\n",
    "for X_batch, y_batch in test_loader:\n",
    "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_batch)\n",
    "        test_loss.append(criterion(logits, y_batch).item())\n",
    "        pred = logits.data.max(dim=1)[1]\n",
    "        correct += pred.eq(y_batch.data).sum()\n",
    "\n",
    "test_loss = sum(test_loss) / len(test_loss)\n",
    "print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct:.0f}/{len(test_loader.dataset)} ({(correct / len(test_loader.dataset)):.2%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkIgJQaLcJvr"
   },
   "source": [
    "**The perfomance of CNN is increased compared to FCNN(98.69% vs 97.69%)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5K_C7gfwHRyE"
   },
   "source": [
    "iii. Calculate the number of learnable parameters and the output shape in each layer. Verify your\n",
    "answers with model summary. (Refer last cell of the tutorial notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZhIDGMgc0ao",
    "outputId": "97085588-04a8-4a53-e1a3-01ea62c909e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d=520\n",
      "Embedding=392100\n",
      "Clf=1010\n",
      "Total=393630\n"
     ]
    }
   ],
   "source": [
    "Conv2d = (1 * 5 * 5 + 1) * 20\n",
    "Embedding = (3920 + 1) * 100\n",
    "Clf = (100 + 1) * 10\n",
    "print(f'{Conv2d=}\\n{Embedding=}\\n{Clf=}\\nTotal={Conv2d + Embedding + Clf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSm6qITDHRyF",
    "outputId": "1f741424-4d9f-4a52-b543-64ac5efdc2b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ConvNet                                  [200, 10]                 --\n",
       "├─Sequential: 1-1                        [200, 10]                 --\n",
       "│    └─Conv2d: 2-1                       [200, 20, 28, 28]         520\n",
       "│    └─ReLU: 2-2                         [200, 20, 28, 28]         --\n",
       "│    └─MaxPool2d: 2-3                    [200, 20, 14, 14]         --\n",
       "│    └─Flatten: 2-4                      [200, 3920]               --\n",
       "│    └─Linear: 2-5                       [200, 100]                392,100\n",
       "│    └─ReLU: 2-6                         [200, 100]                --\n",
       "│    └─Linear: 2-7                       [200, 10]                 1,010\n",
       "==========================================================================================\n",
       "Total params: 393,630\n",
       "Trainable params: 393,630\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 160.16\n",
       "==========================================================================================\n",
       "Input size (MB): 0.63\n",
       "Forward/backward pass size (MB): 25.26\n",
       "Params size (MB): 1.57\n",
       "Estimated Total Size (MB): 27.47\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUwoAwqEgTj9"
   },
   "source": [
    "**Everything is correct**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c617624a7fd88b4018bd9e75be0d58c4afb6a334791d511af9b9a5162b5af2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
